name: CI & Testing

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

jobs:
  test:
    name: Test Python ${{ matrix.python-version }}
    runs-on: ubuntu-22.04
    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11', '3.12', '3.13']

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        python -m pip install -e ".[dev]"

    - name: Run tests
      run: |
        pytest tests/ --cov=transmog

    - name: Test output format methods
      run: |
        cat > test_output_formats.py << 'EOF'
        import sys
        import tempfile
        import os
        import json
        from pathlib import Path
        import transmog as tm

        # Sample data
        data = {
            'id': 123,
            'name': 'Test',
            'details': {'value': 456},
            'items': [{'id': 1}, {'id': 2}]
        }

        # Process data with default API
        result = tm.flatten(data, name='test_entity')

        # Test basic access patterns
        print("Testing basic result access...")
        print(f"Main table records: {len(result.main)}")
        print(f"Child tables: {len(result.tables)}")
        print(f"All tables: {list(result.all_tables.keys())}")

        # Test result iteration and access
        print("Testing result iteration...")
        for record in result:
            print(f"Record ID: {record.get('_id', 'N/A')}")
            break  # Just test first record

        # Test table access methods
        print("Testing table access methods...")
        main_data = result.get_table('main')
        if main_data:
            print(f"Got main table with {len(main_data)} records")

        # Test table info
        table_info = result.table_info()
        print(f"Table info: {table_info}")

        # Create temp directory for testing file outputs
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)

            # Test JSON file output
            print("Testing JSON file output...")
            json_file = temp_path / "test_output.json"
            result.save(json_file, output_format='json')

            if json_file.exists():
                print(f"JSON file created: {json_file}")
                with open(json_file) as f:
                    json_data = json.load(f)
                    print(f"JSON contains {len(json_data)} records")

            # Test CSV file output
            print("Testing CSV file output...")
            csv_file = temp_path / "test_output.csv"
            try:
                result.save(csv_file, output_format='csv')
                if csv_file.exists():
                    print(f"CSV file created: {csv_file}")
            except Exception as e:
                print(f"CSV save failed: {e}")

            # Test directory output for multiple tables
            print("Testing directory output...")
            output_dir = temp_path / "tables"
            try:
                result.save(output_dir, output_format='json')
                json_files = list(output_dir.glob("*.json"))
                print(f"Created {len(json_files)} JSON files in directory")
            except Exception as e:
                print(f"Directory save failed: {e}")

            # Test the streaming API
            print("Testing streaming API...")
            stream_output_dir = temp_path / 'streaming'
            stream_output_dir.mkdir(exist_ok=True)

            try:
                tm.flatten_stream(
                    data=data,
                    output_path=stream_output_dir,
                    name='streaming_test',
                    output_format='json'
                )

                stream_files = list(stream_output_dir.glob("*.json"))
                if stream_files:
                    print(f"Streaming created {len(stream_files)} files")
                else:
                    print("No streaming files created")
            except Exception as e:
                print(f"Streaming failed: {e}")

            # Test file processing
            print("Testing file processing...")
            source_json_path = temp_path / 'source_data.json'
            with open(source_json_path, 'w') as f:
                json.dump(data, f)

            try:
                file_result = tm.flatten_file(source_json_path, name='file_test')
                print(f"File processing: {len(file_result.main)} records")
            except Exception as e:
                print(f"File processing failed: {e}")

        # Test different API options
        print("Testing API options...")

        # Test different array handling
        try:
            result_inline = tm.flatten(data, name='inline_test', arrays='inline')
            print(f"Inline arrays: {len(result_inline.main)} records")
        except Exception as e:
            print(f"Inline arrays failed: {e}")

        try:
            result_skip = tm.flatten(data, name='skip_test', arrays='skip')
            print(f"Skip arrays: {len(result_skip.main)} records")
        except Exception as e:
            print(f"Skip arrays failed: {e}")

        # Test custom separator
        try:
            result_dot = tm.flatten(data, name='dot_test', separator='.')
            print(f"Dot separator: {len(result_dot.main)} records")
        except Exception as e:
            print(f"Dot separator failed: {e}")

        # Test performance options
        try:
            result_memory = tm.flatten(data, name='memory_test', low_memory=True)
            print(f"Low memory: {len(result_memory.main)} records")
        except Exception as e:
            print(f"Low memory failed: {e}")

        # Test error handling
        try:
            result_skip_errors = tm.flatten(data, name='error_test', errors='skip')
            print(f"Skip errors: {len(result_skip_errors.main)} records")
        except Exception as e:
            print(f"Skip errors failed: {e}")

        print('All output format methods working!')
        EOF
        python test_output_formats.py

    # Only build docs on Python 3.9 to verify they build correctly during CI
    - name: Build docs
      if: matrix.python-version == '3.9'
      run: |
        python -m pip install -e ".[docs]"
        cd docs && make html

    - name: Upload docs
      uses: actions/upload-artifact@v4
      if: matrix.python-version == '3.9'
      with:
        name: docs-html
        path: docs/_build/html/

  package:
    runs-on: ubuntu-latest
    needs: [test]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install build dependencies
      run: |
        python -m pip install --upgrade pip
        python -m pip install build wheel twine

    - name: Build package
      run: |
        python -m build

    - name: Test package
      run: |
        python -m twine check dist/*

    - name: Upload package artifacts
      uses: actions/upload-artifact@v4
      with:
        name: dist
        path: dist/
