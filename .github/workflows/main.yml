name: CI & Testing

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

jobs:
  test:
    name: Test Python ${{ matrix.python-version }}
    runs-on: ubuntu-22.04
    strategy:
      matrix:
        python-version: ['3.10', '3.11', '3.12', '3.13', '3.14']

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'

    - name: Verify poetry.lock is in sync
      if: matrix.python-version == '3.10'
      run: |
        python -m pip install --upgrade pip
        python -m pip install poetry
        poetry check --lock

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        python -m pip install -e ".[dev]"

    - name: Run tests
      run: |
        pytest tests/ --cov=transmog

    - name: Test output format methods
      run: |
        cat > test_output_formats.py << 'EOF'
        import sys
        import tempfile
        import os
        import json
        from pathlib import Path
        import transmog as tm

        # Sample data
        data = {
            'id': 123,
            'name': 'Test',
            'details': {'value': 456},
            'items': [{'id': 1}, {'id': 2}]
        }

        # Process data with default API
        result = tm.flatten(data, name='test_entity')

        # Test basic access patterns
        print("Testing basic result access...")
        print(f"Main table records: {len(result.main)}")
        print(f"Child tables: {len(result.tables)}")
        print(f"All tables: {list(result.all_tables.keys())}")

        # Test result iteration and access
        print("Testing result iteration...")
        for record in result.main:
            print(f"Record ID: {record.get('_id', 'N/A')}")
            break  # Just test first record

        # Test length operator
        print(f"Result length: {len(result.main)}")

        # Create temp directory for testing file outputs
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)

            # Test CSV file output
            print("Testing CSV file output...")
            csv_file = temp_path / "test_output.csv"
            result.save(csv_file, output_format='csv')
            if csv_file.exists():
                print(f"CSV file created: {csv_file}")

            # Test Parquet file output
            print("Testing Parquet file output...")
            try:
                parquet_file = temp_path / "test_output.parquet"
                result.save(parquet_file, output_format='parquet')
                if parquet_file.exists():
                    print(f"Parquet file created: {parquet_file}")
            except ImportError:
                print("PyArrow not available, skipping Parquet test")

            # Test directory output for multiple tables
            print("Testing directory output...")
            output_dir = temp_path / "tables"
            paths = result.save(output_dir, output_format='csv')
            print(f"Created {len(paths)} CSV files in directory")

            # Test the streaming API
            print("Testing streaming API...")
            stream_output_dir = temp_path / 'streaming'
            stream_output_dir.mkdir(exist_ok=True)

            tm.flatten_stream(
                data,
                output_path=stream_output_dir,
                name='streaming_test',
                output_format='csv'
            )
            stream_files = list(stream_output_dir.glob("*.csv"))
            print(f"Streaming created {len(stream_files)} files")

            # Test file processing
            print("Testing file processing...")
            source_json_path = temp_path / 'source_data.json'
            with open(source_json_path, 'w') as f:
                json.dump(data, f)

            file_result = tm.flatten(source_json_path, name='file_test')
            print(f"File processing: {len(file_result.main)} records")

        # Test different configuration options
        print("Testing configuration options...")

        # Test different array handling modes
        config_inline = tm.TransmogConfig(array_mode=tm.ArrayMode.INLINE)
        result_inline = tm.flatten(data, name='inline_test', config=config_inline)
        print(f"Inline arrays: {len(result_inline.main)} records")

        config_skip = tm.TransmogConfig(array_mode=tm.ArrayMode.SKIP)
        result_skip = tm.flatten(data, name='skip_test', config=config_skip)
        print(f"Skip arrays: {len(result_skip.main)} records")

        # Test memory-optimized configuration
        config_memory = tm.TransmogConfig(batch_size=100)
        result_memory = tm.flatten(data, name='memory_test', config=config_memory)
        print(f"Memory optimized: {len(result_memory.main)} records")

        # Test null handling configurations
        config_include_nulls = tm.TransmogConfig(include_nulls=True)
        result_include = tm.flatten(data, name='nulls_test', config=config_include_nulls)
        print(f"Include nulls: {len(result_include.main)} records")

        print('All API methods working correctly!')
        EOF
        python test_output_formats.py

    # Only build docs on Python 3.10 to verify they build correctly during CI
    - name: Build docs
      if: matrix.python-version == '3.10'
      run: |
        python -m pip install -e ".[docs]"
        cd docs && make html

    - name: Upload docs
      uses: actions/upload-artifact@v4
      if: matrix.python-version == '3.10'
      with:
        name: docs-html
        path: docs/_build/html/
